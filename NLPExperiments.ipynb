{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN36sdAtRhvZDMTvdCnF7ch"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOEpQ3kynCVN",
        "outputId": "c883572c-19b9-43c0-b450-ad9a993fe921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Places',\n",
              " 'I',\n",
              " 'love',\n",
              " 'to',\n",
              " 'visit',\n",
              " 'the',\n",
              " 'city',\n",
              " 'walls',\n",
              " 'of',\n",
              " '#Dubrovnik',\n",
              " '#endlessroaming',\n",
              " '#travel',\n",
              " '#Croatia']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "tweet = \"Places I love to visit the city walls of #Dubrovnik #endlessroaming #travel #Croatia\"\n",
        "\n",
        "tokenizer.tokenize(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MnuH2f09nGlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2 = \"@online_content @covid-19 @upGrad#WFH#Vaccination\"\n",
        "\n",
        "tokenizer.tokenize(tweet2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZut-unJnHK7",
        "outputId": "188c98ec-bd0b-439f-bfc6-b455aef1bc38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@online_content', '@covid', '-', '19', '@upGrad', '#WFH', '#Vaccination']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86gxildCvMt0",
        "outputId": "71bd7f1a-871a-45f9-f4b0-e290bfa3c35c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        " \n",
        "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
        "data1 = \"Working-professionals are learning.\"\n",
        "data2 = \"DataScience course from @upGrad.\"\n",
        "words1 = word_tokenize(data1)\n",
        "words2 = word_tokenize(data2)\n",
        "print(words1)\n",
        "print(words2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GigWSpWKs3uR",
        "outputId": "cc817769-ab24-4534-cae9-5fb47b70d7bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Working-professionals', 'are', 'learning', '.']\n",
            "['DataScience', 'course', 'from', '@', 'upGrad', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Combine the two sentences\n",
        "b. Lowercasing\n",
        "c. Stopword Removal\n",
        "d. Replacing punctuations by a single space"
      ],
      "metadata": {
        "id": "gELnJAkKwTQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wr41OTGvyga",
        "outputId": "100151fd-4bd1-49f8-9642-f4c7b7377aeb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "data3 = data1 + \" \" + data2\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d-VFqnfw_gF",
        "outputId": "d6551230-628f-4102-cb00-f3666a5627c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working-professionals are learning. DataScience course from @upGrad.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = data3\n",
        "translate_table = dict((ord(char), None) for char in string.punctuation)   \n",
        "s.translate(translate_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CQB5SDPB2fHa",
        "outputId": "accf1a88-b685-49b0-aefe-c03485d35551"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Workingprofessionals are learning DataScience course from upGrad'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data4 = s.translate(translate_table)\n",
        "print(data4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onn2KYZn3Fq7",
        "outputId": "108f57d2-762e-403d-a028-f0660ee24666"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workingprofessionals are learning DataScience course from upGrad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = word_tokenize(data4)\n",
        "print(word_tokens)\n",
        "print(type(word_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkR7ZIAh2bMh",
        "outputId": "30a9ee11-f541-406b-f76c-40b54341b08a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Workingprofessionals', 'are', 'learning', 'DataScience', 'course', 'from', 'upGrad']\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        " \n",
        "print(word_tokens)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE36PMXX2M5W",
        "outputId": "67c53bad-208c-4e0d-de68-bf062bcf0b4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Workingprofessionals', 'are', 'learning', 'DataScience', 'course', 'from', 'upGrad']\n",
            "['Workingprofessionals', 'learning', 'DataScience', 'course', 'upGrad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigrm = list(nltk.bigrams(filtered_sentence))\n",
        "print(len(bigrm))\n",
        "print(bigrm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CstQwtM-yCem",
        "outputId": "09bd5321-707f-4250-880a-bf9739158c60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "[('Workingprofessionals', 'learning'), ('learning', 'DataScience'), ('DataScience', 'course'), ('course', 'upGrad')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above was wrong:\n",
        "\n",
        "This is the correct answer:\n",
        "\n",
        "Let’s combine the two sentences first:\n",
        "\n",
        "Working-professionals are learning DataScience course from @upGrad.”\n",
        "\n",
        " \n",
        "\n",
        "When you do the lowercasing, you get the following sentence.\n",
        "\n",
        "“working-professionals are learning datascience course from @upgrad.”\n",
        "\n",
        " \n",
        "\n",
        "When you remove the stop words, you get the following sentence.\n",
        "\n",
        "“working-professionals learning datascience course @upgrad”\n",
        "\n",
        " \n",
        "\n",
        "After replacing the punctuation by single space you get:\n",
        "\n",
        "“working professionals learning datascience course upgrad”\n",
        "\n",
        " \n",
        "\n",
        "Hence, you have a total of 5 bigrams, which are ‘working professionals’, ‘professionals learning’, ‘learning datascience’, ‘datascience course’, ‘course upgrad’."
      ],
      "metadata": {
        "id": "7m2znjm84hXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words3 = word_tokenize(data3.lower())\n",
        "print(words3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o723q4SJxbuh",
        "outputId": "feab77a5-c713-49bf-d376-13a8ee975c48"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['working-professionals', 'are', 'learning', '.', 'datascience', 'course', 'from', '@', 'upgrad', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VSnJeDwkyqnD"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cmVpyanP4fD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "re86Hqb_v_Ji"
      }
    }
  ]
}